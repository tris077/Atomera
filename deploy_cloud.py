#!/usr/bin/env python3
"""
Cloud deployment script for Atomera.
Automatically configures the backend for optimal cloud GPU performance.
"""

import os
import sys
import subprocess
from pathlib import Path


def detect_gpu():
    """Detect available GPU and return configuration."""
    try:
        import torch

        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            return {
                "available": True,
                "count": gpu_count,
                "name": gpu_name,
                "memory_gb": round(gpu_memory, 1),
            }
    except ImportError:
        pass

    return {"available": False}


def configure_for_cloud():
    """Configure Atomera for cloud deployment."""
    print("ğŸš€ Configuring Atomera for Cloud Deployment")
    print("=" * 50)

    # Detect GPU
    gpu_info = detect_gpu()

    if gpu_info["available"]:
        print(f"âœ… GPU Detected: {gpu_info['name']}")
        print(f"   Memory: {gpu_info['memory_gb']} GB")
        print(f"   Count: {gpu_info['count']}")

        # Configure for GPU
        accelerator = "gpu"
        devices = min(gpu_info["count"], 2)  # Use up to 2 GPUs
        diffusion_samples = 3 if gpu_info["memory_gb"] >= 20 else 1
        max_jobs = 2 if gpu_info["memory_gb"] >= 20 else 1

    else:
        print("âš ï¸  No GPU detected, using CPU configuration")
        accelerator = "cpu"
        devices = 1
        diffusion_samples = 1
        max_jobs = 1

    # Create environment file
    env_content = f"""# Atomera Cloud Configuration
# Generated by deploy_cloud.py

# Boltz-2 Configuration
ACCELERATOR={accelerator}
DEVICES={devices}
DIFFUSION_SAMPLES={diffusion_samples}
MAX_CONCURRENT_JOBS={max_jobs}
JOB_TIMEOUT_SECONDS=1800

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Performance Settings
USE_MSA_SERVER=true
MAX_SEQUENCE_LENGTH=10000
MAX_SMILES_LENGTH=1000
"""

    env_path = Path("backend/.env")
    env_path.write_text(env_content)
    print(f"âœ… Created configuration file: {env_path}")

    # Print configuration summary
    print("\nğŸ“‹ Configuration Summary:")
    print(f"   Accelerator: {accelerator}")
    print(f"   Devices: {devices}")
    print(f"   Diffusion Samples: {diffusion_samples}")
    print(f"   Max Concurrent Jobs: {max_jobs}")
    print(f"   Job Timeout: 30 minutes")

    return accelerator == "gpu"


def install_dependencies():
    """Install required dependencies."""
    print("\nğŸ“¦ Installing Dependencies")
    print("=" * 30)

    try:
        # Install backend dependencies
        subprocess.run(
            [sys.executable, "-m", "pip", "install", "-r", "backend/requirements.txt"],
            check=True,
        )
        print("âœ… Backend dependencies installed")

        # Install PyTorch with CUDA if GPU is available
        if detect_gpu()["available"]:
            print("ğŸ”§ Installing PyTorch with CUDA support...")
            subprocess.run(
                [
                    sys.executable,
                    "-m",
                    "pip",
                    "install",
                    "torch",
                    "torchvision",
                    "torchaudio",
                    "--index-url",
                    "https://download.pytorch.org/whl/cu118",
                ],
                check=True,
            )
            print("âœ… PyTorch with CUDA installed")

    except subprocess.CalledProcessError as e:
        print(f"âŒ Failed to install dependencies: {e}")
        return False

    return True


def start_backend():
    """Start the Atomera backend."""
    print("\nğŸš€ Starting Atomera Backend")
    print("=" * 30)

    try:
        os.chdir("backend")
        subprocess.run([sys.executable, "main.py"], check=True)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Shutting down Atomera backend")
    except subprocess.CalledProcessError as e:
        print(f"âŒ Failed to start backend: {e}")
        return False

    return True


def main():
    """Main deployment function."""
    print("â˜ï¸  Atomera Cloud Deployment")
    print("=" * 40)

    # Check if we're in the right directory
    if not Path("backend").exists():
        print("âŒ Please run this script from the Atomera root directory")
        sys.exit(1)

    # Configure for cloud
    has_gpu = configure_for_cloud()

    # Install dependencies
    if not install_dependencies():
        sys.exit(1)

    # Print next steps
    print("\nğŸ¯ Next Steps:")
    if has_gpu:
        print("   âœ… GPU configuration detected")
        print("   ğŸš€ Ready for high-performance molecular modeling")
    else:
        print("   âš ï¸  CPU-only configuration")
        print("   ğŸ’¡ Consider using a GPU cloud instance for better performance")

    print("\nğŸŒ Access your API at: http://localhost:8000")
    print("ğŸ“š API docs at: http://localhost:8000/docs")

    # Ask if user wants to start backend
    response = input("\nğŸš€ Start backend now? (y/n): ").lower().strip()
    if response in ["y", "yes"]:
        start_backend()
    else:
        print("\nğŸ’¡ To start manually: cd backend && python main.py")


if __name__ == "__main__":
    main()
