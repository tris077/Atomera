# Atomera API Configuration
# Copy this file to .env and customize the values

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Boltz-2 Configuration
BOLTZ_COMMAND=boltz
USE_MSA_SERVER=true
MAX_SEQUENCE_LENGTH=10000
MAX_SMILES_LENGTH=1000

# Output Configuration
OUTPUT_BASE_DIR=output
PREDICTIONS_DIR=predictions
TEMP_DIR=temp

# Job Configuration
MAX_CONCURRENT_JOBS=4
JOB_TIMEOUT_SECONDS=300

# RunPod Configuration (for GPU inference)
USE_RUNPOD=true
RUNPOD_API_KEY=your_runpod_api_key_here
RUNPOD_ENDPOINT_ID=your_runpod_endpoint_id_here
RUNPOD_POLL_INTERVAL=5
RUNPOD_TIMEOUT=1800

# Optional: Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/atomera.log
